Template Re-write:
* Add compile time parsing of the basis text -> Generate the full generic basis
	* Start with the parsing that the Hartree-Fock program did and see if it can be made constexpr
	* If not, using the compile time parsing that json uses (see constexpr all the things)
* Finish adding at least up to Argon within the STO-NG basis template
	- Modify the overlap & kinetic computations to handle atoms from a generic basis
	- Modify the overlap & kinetic computations to handle the STO-NG template (but don't pre-compute all the intermediates)
	- Modify the overlap & kinetic computations to to handle the STO-NG template and pre-compute all intermediates values
	- Run benchmarks for all of these
* Try creating a template for the 6-31G family of basis sets
	- Can this automatically work with the overlap and kinetic computations? If not, modify them to handle these basis sets









Thoughts:
	* The library should never throw an exception (how is performance affected if we disable exceptions?)
		- If two atoms have the exact same position, we probably need to avoid divide by zero.
		  Instead of the delta being 0, we should probably change it to the minimum non-zero value.
			* Unit test this





Create 2 new projects:
- libint-benchmark:
	* Single main file
	* bash script for building (Release only) - need to link Google benchmark
	* Will only run on Linux

Consider turning myhf into a CMake project. What would we need to do?
	* The main reason being we would like to be able to unit test against libint
      as well as compare benchmarks.





Libint:
	* Figure out how to use the Libint library
	* Benchmark all boys functions (is there a caching/pre-calculated method?)
	* How does accuracy compare?
		- What is the typical range of values we need to calculate?
		- If the range is large, do we need to call more than one function depending on the input value
	* Benchmark overlap/kinetic/nuclear integrals
		- Are they multithreaded or just using vectorization?
	* Would probably be a good idea to use libint as the source for unit tests
		- This way, we can also get away from storing the unit test data in json files


		



DONE -- Understand the code AND math for how the Hartree-Fock program implements the NUC calculation
DONE -- Implement that method for the calculation
	- Figure out what kind of accuracy you're getting with the Boys functions
		- Consider a caching scheme for better/faster Boys calculation
	- Compare accuracy between the Hartree-Fock program and PySCF
* Understand how PySCF implements that calculation 
	- Is the underlying implementation in C?
* Once you are completely done with the NUC calculation, be sure to fully document it in the powerpoint


TRY THIS: QuantumNumbersWithMetadata should not hold the index of prev/prevprev/next. Instead
			it should should have the actual QuantumNumbers
			- Run a benchmark of doing this



* GENERIC implementation:
	- Figure out why my implementation of the Nuc integral differs from both PySCF and the
      Hartree-Fock programs. What is the most accurate way to evaluate the integral?
		~ Probably need to find better literature on it.
	- Probably a good idea to also generate unit test data from PySCF for all integrals
	- Nuclear-electron attraction:
		~ Add unit testing: make sure slow implementation is correct first
		~ Implement faster nuclear-electron attraction computation
			* Get access to the paper the faster version is based on
			* Is there no literature that solves this exactly? Or a faster approximation mechanism?
		~ How does PySCF implement this calculation?
			* Do they cite the literature they followed?
		~ Unit test (both slow and fast implementations)
		~ Add benchmark (also benchmark against slower implementation)
		~ Parallelize the computation?
		~ Finish powerpoint notes for the implementation
	- Electron-electron integral:
		~ Find the paper for this
		~ Add powerpoint notes
		~ Implement the computation
		~ Unit test
		~ Run benchmark
		~ Parallelize the computation?
		~ Finish powerpoint notes (if necessary)
	- Hartree-Fock algorithm
		~ Document the algorithm in powerpoint
		~ Implement the full algorithm
		~ Unit test
		~ Run benchmark
		~ Opportunities to parallelize?
		~ Can any portion be run on the GPU (cuda)?
		~ Read that one paper about Hartree-Fock computation on GPUs
	- Tests:
		~ How accurate are different basis sets? How long do they take to compute?
			* Add support for MANY other basis sets.
			* Add support for more atoms than Calcium (if you think that would be useful)
		~ Once you have a molecule solved, if you change nuclear positions slightly, how 
		  fast is the next computation? In theory, it should be quite a bit faster because
		  you should start with orbitals that are very close to what the final result should be.
			* Generate a graph of nuclear displacement vs. computation time (or nuclear displacement
			  vs. Hartree-Fock iterations) to get an idea of how much longer the computation takes
			  when nuclei move between each iteration.

* Fun extension:
	- Build a modeling application
		~ Build custom molecules and selectively look at electron orbitals
		~ Can we build a web-based application around this?
			* Can you use something like emscriptem?
			* Or would it be better to just do the computation on the backend and then send the
			  results down?
			* How does the 3D modeling on the PDB website work?

* Gradient computation:
	- Understand the one paper that describes gradient computation
	- Are there papers on how to implement?
	- NOTE: pyscf seems to include gradient calculations (see https://github.com/pyscf/pyscf/blob/master/examples/gto/20-ao_integrals.py)
	- Once you have an implementation and have tested multiple basis sets, eventually we should
	  reach an algorithm that is reasonably accurate (whatever that means...), at which point, 
	  we should implement the faster ("data driven") implementation for all the integral calculations
	  for the given basis set we have decided to use.









Unit Tests
	* Right now, unit tests are just set up to make sure we align with the other
		C++ Hartree-Fock program. Ideally, we should assemble as many unit tests
		as we can where the values actually come from the literature (and therefore,
		we should track those citations). 
			- In thinking about it, I feel like such a set of data might already exist,
			  but if not, then it probably should be created.